import json
import openai
import requests
from typing import List, Dict, Optional
import time
import os
import datetime
from dataclasses import dataclass

@dataclass
class EmotionResult:
    """æƒ…æ„Ÿåˆ†æç»“æœ"""
    line: int
    text: str
    emotion: str
    confidence: float
    reasoning: str

class LLMEmotionAnalyzer:
    def __init__(self, file_path: str, emovoice_api_config: Dict):
        self.file_path = file_path
        self.emovoice_api_config = emovoice_api_config
        self.data = []
        self.chunk_size = 1000
        self.api_requests_log = []
        
        # ä¿®æ”¹è¾“å‡ºé€»è¾‘ï¼šç›´æ¥ä¿å­˜åœ¨åŸå§‹JSONæ–‡ä»¶æ‰€åœ¨ç›®å½•
        input_dir = os.path.dirname(os.path.abspath(file_path))
        input_basename = os.path.splitext(os.path.basename(file_path))[0]
        
        # ä¸å†åˆ›å»ºå•ç‹¬çš„emotion_analysisæ–‡ä»¶å¤¹ï¼Œç›´æ¥åœ¨åŒçº§ç›®å½•ä¸‹ç”Ÿæˆæ–‡ä»¶
        self.output_dir = input_dir  # ç›´æ¥ä½¿ç”¨è¾“å…¥æ–‡ä»¶æ‰€åœ¨ç›®å½•
        
        # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆæ·»åŠ _emotion_analysisåç¼€ä»¥åŒºåˆ†ï¼‰
        self.output_json_file = os.path.join(self.output_dir, f'{input_basename}_emotion_analysis_detailed.json')
        self.output_summary_file = os.path.join(self.output_dir, f'{input_basename}_emotion_analysis_summary.txt')
        self.api_log_file = os.path.join(self.output_dir, f'{input_basename}_emotion_analysis_api_log.json')
        
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ç»“æœæ–‡ä»¶: {self.output_json_file}")
        print(f"æ‘˜è¦æ–‡ä»¶: {self.output_summary_file}")
        print(f"APIæ—¥å¿—æ–‡ä»¶: {self.api_log_file}")
    
    def load_data(self):
        """åŠ è½½JSONæ•°æ®ï¼Œæå–textå­—æ®µå’Œè¡Œå·"""
        try:
            with open(self.file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            # ä»resultså­—æ®µä¸­æå–æ•°æ®
            if 'results' in data:
                for item in data['results']:
                    text_content = item.get('text', '').strip()
                    if text_content:  # åªä¿å­˜æœ‰æ–‡æœ¬å†…å®¹çš„è®°å½•
                        self.data.append({
                            'line': item.get('line', 0),
                            'text': text_content,
                            'speaker': item.get('speaker', 'Unknown')
                        })
            else:
                print("é”™è¯¯ï¼šJSONæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°'results'å­—æ®µ")
                return False
                
            print(f"å·²åŠ è½½ {len(self.data)} æ¡æœ‰æ•ˆæ–‡æœ¬è®°å½•")
            return True
        except Exception as e:
            print(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return False
    
    def log_api_request(self, request_data: Dict, response_data: Dict, chunk_info: Dict):
        """è®°å½•APIè¯·æ±‚å’Œå“åº”"""
        log_entry = {
            "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "chunk_info": chunk_info,
            "request": request_data,
            "response": response_data
        }
        self.api_requests_log.append(log_entry)
    
    def save_api_logs(self):
        """ä¿å­˜APIè¯·æ±‚æ—¥å¿—"""
        try:
            with open(self.api_log_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "total_requests": len(self.api_requests_log),
                    "requests": self.api_requests_log
                }, f, ensure_ascii=False, indent=2)
            print(f"APIè¯·æ±‚æ—¥å¿—å·²ä¿å­˜åˆ°: {self.api_log_file}")
        except Exception as e:
            print(f"ä¿å­˜APIæ—¥å¿—å¤±è´¥: {e}")
    
    def call_deepseek_api(self, prompt: str, chunk_info: Dict) -> str:
        """è°ƒç”¨DeepSeek API"""
        try:
            print("æ­£åœ¨åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯...")
            
            base_url = self.emovoice_api_config.get('deepseek_base_url', 'https://api.deepseek.com')
            print(f"ä½¿ç”¨APIåœ°å€: {base_url}")
            
            client = openai.OpenAI(
                api_key=self.emovoice_api_config['deepseek_api_key'],
                base_url=base_url
            )
            
            model = self.emovoice_api_config.get('deepseek_model', 'deepseek-chat')
            print(f"ä½¿ç”¨æ¨¡å‹: {model}")
            print(f"æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            print("å¼€å§‹å‘é€APIè¯·æ±‚...")
            
            # å‡†å¤‡è¯·æ±‚æ•°æ®
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†ææä¾›çš„ç¾è‚¡è´¢æŠ¥ç”µè¯ä¼šè®®æ–‡æœ¬ï¼Œè¯†åˆ«æ¯å¥è¯çš„æƒ…æ„Ÿã€‚è¯·ç”¨è‹±æ–‡å›ç­”ã€‚"},
                {"role": "user", "content": prompt}
            ]
            
            request_data = {
                "model": model,
                "messages": messages,
                "temperature": 0.1,
                "max_tokens": 4000,
                "stream": False,
                "timeout": 120
            }
            
            start_time = time.time()
            
            response = client.chat.completions.create(**request_data)
            
            end_time = time.time()
            response_content = response.choices[0].message.content
            
            print(f"APIè°ƒç”¨æˆåŠŸï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")
            print(f"å“åº”é•¿åº¦: {len(response_content)} å­—ç¬¦")
            
            # è®°å½•APIè¯·æ±‚å’Œå“åº”
            response_data = {
                "success": True,
                "response_time": end_time - start_time,
                "content": response_content,
                "content_length": len(response_content),
                "usage": {
                    "prompt_tokens": getattr(response.usage, 'prompt_tokens', 0),
                    "completion_tokens": getattr(response.usage, 'completion_tokens', 0),
                    "total_tokens": getattr(response.usage, 'total_tokens', 0)
                } if hasattr(response, 'usage') else None
            }
            
            self.log_api_request(request_data, response_data, chunk_info)
            
            return response_content
        except Exception as e:
            print(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {type(e).__name__}: {e}")
            
            # è®°å½•å¤±è´¥çš„APIè¯·æ±‚
            error_response = {
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__
            }
            
            self.log_api_request(request_data if 'request_data' in locals() else {}, error_response, chunk_info)
            
            return None
    
    def call_openai_api(self, prompt: str, chunk_info: Dict, model: str = "gpt-4") -> str:
        """è°ƒç”¨OpenAI API"""
        try:
            client = openai.OpenAI(
                api_key=self.emovoice_api_config['openai_api_key'],
                base_url=self.emovoice_api_config.get('openai_base_url')
            )
            
            messages = [
                {"role": "system", "content": "You are a professional emotion analysis expert. Please carefully analyze the provided US earnings call text and identify the emotion in each sentence."},
                {"role": "user", "content": prompt}
            ]
            
            request_data = {
                "model": model,
                "messages": messages,
                "temperature": 0.1,
                "max_tokens": 4000
            }
            
            start_time = time.time()
            
            response = client.chat.completions.create(**request_data)
            
            end_time = time.time()
            response_content = response.choices[0].message.content
            
            # è®°å½•APIè¯·æ±‚å’Œå“åº”
            response_data = {
                "success": True,
                "response_time": end_time - start_time,
                "content": response_content,
                "content_length": len(response_content),
                "usage": {
                    "prompt_tokens": getattr(response.usage, 'prompt_tokens', 0),
                    "completion_tokens": getattr(response.usage, 'completion_tokens', 0),
                    "total_tokens": getattr(response.usage, 'total_tokens', 0)
                } if hasattr(response, 'usage') else None
            }
            
            self.log_api_request(request_data, response_data, chunk_info)
            
            return response_content
        except Exception as e:
            print(f"OpenAI APIè°ƒç”¨å¤±è´¥: {e}")
            
            # è®°å½•å¤±è´¥çš„APIè¯·æ±‚
            error_response = {
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__
            }
            
            self.log_api_request(request_data if 'request_data' in locals() else {}, error_response, chunk_info)
            
            return None
    
    def call_api(self, prompt: str, chunk_info: Dict) -> str:
        """æ ¹æ®é…ç½®è°ƒç”¨ç›¸åº”çš„API"""
        api_type = self.emovoice_api_config.get('api_type', 'deepseek')
        print(f"å½“å‰APIç±»å‹: {api_type}")
        
        if api_type == 'openai':
            print("è°ƒç”¨OpenAI API...")
            return self.call_openai_api(prompt, chunk_info)
        elif api_type == 'deepseek':
            print("è°ƒç”¨DeepSeek API...")
            return self.call_deepseek_api(prompt, chunk_info)
        else:
            print(f"ä¸æ”¯æŒçš„APIç±»å‹: {api_type}")
            return None
    
    def generate_emotion_analysis_prompt(self, chunk_data: List[Dict]) -> str:
        """ç”Ÿæˆæƒ…æ„Ÿåˆ†ææç¤ºè¯"""
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬ä¸­æ¯å¥è¯çš„æƒ…æ„Ÿè‰²å½©ã€‚

éœ€è¦åˆ†æçš„æ–‡æœ¬ï¼ˆå…±{len(chunk_data)}è¡Œï¼‰ï¼š
"""
        
        # æ·»åŠ æ–‡æœ¬å†…å®¹
        for item in chunk_data:
            prompt += f"\nç¬¬{item['line']}è¡Œ: {item['text']}"
        
        prompt += f"""\n\nä»»åŠ¡ï¼šåˆ†ææ¯è¡Œæ–‡æœ¬çš„æƒ…æ„Ÿã€‚å¯¹äºæ¯ä¸€è¡Œï¼Œä»ä»¥ä¸‹æƒ…æ„Ÿç±»åˆ«ä¸­è¯†åˆ«ä¸»è¦æƒ…æ„Ÿï¼š
- happinessï¼ˆå¿«ä¹ï¼‰: ç§¯æã€ä¹è§‚ã€è‡ªä¿¡ã€æ»¡æ„çš„æƒ…ç»ª
- sadnessï¼ˆæ‚²ä¼¤ï¼‰: å¤±æœ›ã€æ‹…å¿§ã€é—æ†¾ã€å¿§éƒçš„æƒ…ç»ª
- angerï¼ˆæ„¤æ€’ï¼‰: æŒ«æŠ˜ã€æ¼æ€’ã€æ‰¹è¯„ã€å¼ºçƒˆåå¯¹çš„æƒ…ç»ª
- fearï¼ˆææƒ§ï¼‰: æ‹…å¿ƒã€ç„¦è™‘ã€ä¸ç¡®å®šã€å¯¹é£é™©çš„è°¨æ…
- surpriseï¼ˆæƒŠè®¶ï¼‰: æ„å¤–çš„ç»“æœã€éœ‡æƒŠã€æƒŠå¥‡
- disgustï¼ˆåŒæ¶ï¼‰: å¼ºçƒˆçš„ä¸èµæˆã€æ‹’ç»ã€åæ„Ÿ
- noneï¼ˆä¸­æ€§ï¼‰: ä¸­æ€§ã€äº‹å®æ€§æˆ–æ²¡æœ‰æ˜æ˜¾æƒ…æ„Ÿè‰²å½©

é‡è¦æé†’ï¼šæ¯ä¸ªè¡Œå·å¿…é¡»ä¸”åªèƒ½å‡ºç°åœ¨ä¸€ä¸ªæƒ…æ„Ÿç±»åˆ«ä¸­ã€‚ä¸è¦åœ¨ä¸åŒæƒ…æ„Ÿä¸­é‡å¤è¡Œå·ã€‚

è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼ŒæŒ‰æƒ…æ„Ÿåˆ†ç»„ï¼‰ï¼š
happiness: è¡Œå·ç”¨é€—å·åˆ†éš”
sadness: è¡Œå·ç”¨é€—å·åˆ†éš”
anger: è¡Œå·ç”¨é€—å·åˆ†éš”
fear: è¡Œå·ç”¨é€—å·åˆ†éš”
surprise: è¡Œå·ç”¨é€—å·åˆ†éš”
disgust: è¡Œå·ç”¨é€—å·åˆ†éš”
none: è¡Œå·ç”¨é€—å·åˆ†éš”

ç¤ºä¾‹ï¼š
happiness: 13,14,15,16
sadness: 12,18,19
anger: 4,5,20
fear: 10,17
surprise: 8
disgust: 9,11
none: 1,2,3,6,7

è¯·å®¢è§‚åˆ†ææ¯ä¸€è¡Œï¼Œå°†æ¯ä¸ªè¡Œå·åˆ†é…åˆ°æ°å¥½ä¸€ä¸ªæƒ…æ„Ÿç±»åˆ«ä¸­ã€‚ç¡®ä¿ä»ç¬¬{chunk_data[0]['line']}è¡Œåˆ°ç¬¬{chunk_data[-1]['line']}è¡Œçš„æ‰€æœ‰è¡Œå·éƒ½è¢«åŒ…å«ï¼Œä¸”æ²¡æœ‰è¡Œå·å‡ºç°ä¸¤æ¬¡ã€‚"""
        
        return prompt
    
    def parse_emotion_response(self, response_text: str, chunk_data: List[Dict]) -> List[Dict]:
        """è§£æAPIå“åº”çš„æƒ…æ„Ÿåˆ†æç»“æœ"""
        try:
            response_text = response_text.strip()
            
            # è§£ææƒ…æ„Ÿç»“æœ
            import re
            emotion_results = []
            used_line_numbers = set()  # è·Ÿè¸ªå·²ä½¿ç”¨çš„è¡Œå·
            
            # åˆ›å»ºè¡Œå·åˆ°æ•°æ®çš„æ˜ å°„
            line_to_data = {item['line']: item for item in chunk_data}
            
            # è§£ææŒ‰æƒ…ç»ªåˆ†ç»„çš„æ ¼å¼
            lines = response_text.split('\n')
            for line in lines:
                line = line.strip()
                if ':' in line:
                    parts = line.split(':', 1)
                    if len(parts) == 2:
                        emotion = parts[0].strip().lower()
                        line_numbers_str = parts[1].strip()
                        
                        # éªŒè¯æƒ…æ„Ÿç±»å‹
                        valid_emotions = ['happiness', 'sadness', 'anger', 'fear', 'surprise', 'disgust', 'none']
                        if emotion not in valid_emotions:
                            continue
                        
                        # è§£æè¡Œå·
                        if line_numbers_str:  # å¦‚æœä¸ä¸ºç©º
                            try:
                                line_numbers = [int(x.strip()) for x in line_numbers_str.split(',') if x.strip()]
                                for line_num in line_numbers:
                                    # æ£€æŸ¥é‡å¤
                                    if line_num in used_line_numbers:
                                        print(f"âš ï¸  è­¦å‘Šï¼šè¡Œå· {line_num} é‡å¤å‡ºç°ï¼Œè·³è¿‡åç»­å‡ºç°")
                                        continue
                                    
                                    if line_num in line_to_data:
                                        emotion_results.append({
                                            "line": line_num,
                                            "text": line_to_data[line_num]['text'],
                                            "speaker": line_to_data[line_num]['speaker'],
                                            "emotion": emotion
                                        })
                                        used_line_numbers.add(line_num)
                            except ValueError:
                                # å¦‚æœè§£æè¡Œå·å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸€è¡Œ
                                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„è¡Œå·
            expected_lines = set(item['line'] for item in chunk_data)
            missing_lines = expected_lines - used_line_numbers
            if missing_lines:
                print(f"âš ï¸  è­¦å‘Šï¼šä»¥ä¸‹è¡Œå·æœªè¢«åˆ†æï¼š{sorted(missing_lines)}")
                # å°†é—æ¼çš„è¡Œå·å½’ç±»ä¸º 'none'
                for line_num in missing_lines:
                    emotion_results.append({
                        "line": line_num,
                        "text": line_to_data[line_num]['text'],
                        "speaker": line_to_data[line_num]['speaker'],
                        "emotion": "none"
                    })
            
            print(f"æˆåŠŸè§£æ {len(emotion_results)} æ¡æƒ…æ„Ÿåˆ†æç»“æœ")
            return emotion_results
            
        except Exception as e:
            print(f"è§£æAPIå“åº”å¤±è´¥: {e}")
            return []
    
    def generate_emotion_summary(self, results: List[Dict]) -> Dict:
        """ç”ŸæˆæŒ‰æƒ…ç»ªåˆ†ç»„çš„æ‘˜è¦"""
        emotion_groups = {
            'happiness': [],
            'sadness': [],
            'anger': [],
            'fear': [],
            'surprise': [],
            'disgust': [],
            'none': []
        }
        
        # æŒ‰æƒ…ç»ªåˆ†ç»„
        for result in results:
            emotion = result['emotion']
            if emotion in emotion_groups:
                emotion_groups[emotion].append(result['line'])
        
        # æ’åºè¡Œå·
        for emotion in emotion_groups:
            emotion_groups[emotion].sort()
        
        return emotion_groups
    
    def save_emotion_summary(self, emotion_groups: Dict):
        """ä¿å­˜æƒ…ç»ªæ‘˜è¦åˆ°æ–‡æœ¬æ–‡ä»¶"""
        try:
            with open(self.output_summary_file, 'w', encoding='utf-8') as f:
                f.write("=== æƒ…æ„Ÿåˆ†ææ‘˜è¦ ===\n\n")
                
                for emotion, lines in emotion_groups.items():
                    if lines:  # åªæ˜¾ç¤ºæœ‰æ•°æ®çš„æƒ…ç»ª
                        line_str = ','.join(map(str, lines))
                        f.write(f"{emotion}: {line_str}\n")
                    else:
                        f.write(f"{emotion}: æ— \n")
                
                f.write(f"\næ€»è®¡åˆ†æè¡Œæ•°: {sum(len(lines) for lines in emotion_groups.values())}\n")
            
            print(f"æƒ…ç»ªæ‘˜è¦å·²ä¿å­˜åˆ°: {self.output_summary_file}")
            
        except Exception as e:
            print(f"ä¿å­˜æƒ…ç»ªæ‘˜è¦å¤±è´¥: {e}")
    
    def run_emotion_analysis(self) -> Dict:
        """è¿è¡Œæƒ…æ„Ÿåˆ†æ"""
        try:
            # 1. åŠ è½½æ•°æ®
            if not self.load_data():
                return None
            
            if not self.data:
                print("âŒ æ²¡æœ‰åŠ è½½åˆ°æœ‰æ•ˆæ•°æ®")
                return None
            
            # 2. åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ†å—å¤„ç†
            if len(self.data) <= self.chunk_size:
                print(f"æ•°æ®é‡ {len(self.data)} è¡Œï¼Œæ— éœ€åˆ†å—å¤„ç†")
                total_chunks = 1
                chunks = [self.data]
            else:
                print(f"æ•°æ®é‡ {len(self.data)} è¡Œï¼Œè¶…è¿‡ {self.chunk_size} è¡Œï¼Œå¼€å§‹åˆ†å—å¤„ç†")
                total_chunks = (len(self.data) + self.chunk_size - 1) // self.chunk_size
                chunks = [self.data[i:i + self.chunk_size] for i in range(0, len(self.data), self.chunk_size)]
            
            # 3. å¤„ç†æ•°æ®å—
            all_emotion_results = []
            
            for chunk_idx, chunk_data in enumerate(chunks):
                chunk_num = chunk_idx + 1
                chunk_info = {
                    "chunk_number": chunk_num,
                    "total_chunks": total_chunks,
                    "chunk_size": len(chunk_data),
                    "start_line": chunk_data[0]['line'],
                    "end_line": chunk_data[-1]['line']
                }
                
                print(f"\nå¤„ç†ç¬¬ {chunk_num}/{total_chunks} å— (è¡Œ {chunk_info['start_line']}-{chunk_info['end_line']})")
                
                # ç”Ÿæˆæç¤ºè¯
                prompt = self.generate_emotion_analysis_prompt(chunk_data)
                
                # è°ƒç”¨API
                api_response = self.call_api(prompt, chunk_info)
                if not api_response:
                    print(f"âŒ ç¬¬ {chunk_num} å—APIè°ƒç”¨å¤±è´¥")
                    continue
                
                # è§£æå“åº”
                chunk_results = self.parse_emotion_response(api_response, chunk_data)
                if chunk_results:
                    all_emotion_results.extend(chunk_results)
                    print(f"âœ… ç¬¬ {chunk_num} å—å¤„ç†å®Œæˆï¼Œè·å¾— {len(chunk_results)} æ¡ç»“æœ")
                else:
                    print(f"âŒ ç¬¬ {chunk_num} å—è§£æå¤±è´¥")
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™æµ
                if chunk_num < total_chunks:
                    print("ç­‰å¾…2ç§’é¿å…APIé™æµ...")
                    time.sleep(2)
            
            # 4. ç”Ÿæˆæƒ…ç»ªæ‘˜è¦
            emotion_groups = self.generate_emotion_summary(all_emotion_results)
            
            # 5. æ•´ç†æœ€ç»ˆç»“æœ
            final_result = {
                "total_lines": len(self.data),
                "processed_lines": len(all_emotion_results),
                "api_type": self.emovoice_api_config.get('api_type', 'unknown'),
                "processing_method": "chunked_emotion_analysis",
                "chunk_size": self.chunk_size,
                "total_chunks": total_chunks,
                "emotion_summary": emotion_groups,
                "results": sorted(all_emotion_results, key=lambda x: x['line'])
            }
            
            # 6. ä¿å­˜ç»“æœ
            with open(self.output_json_file, 'w', encoding='utf-8') as f:
                json.dump(final_result, f, ensure_ascii=False, indent=2)
            
            # 7. ä¿å­˜æƒ…ç»ªæ‘˜è¦
            self.save_emotion_summary(emotion_groups)
            
            # 8. ä¿å­˜APIæ—¥å¿—
            self.save_api_logs()
            
            print(f"\nâœ… æƒ…æ„Ÿåˆ†æå®Œæˆï¼")
            print(f"ğŸ“Š æ€»è®¡å¤„ç†: {final_result['processed_lines']}/{final_result['total_lines']} è¡Œ")
            print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {self.output_json_file}")
            print(f"ğŸ“ æ‘˜è¦å·²ä¿å­˜åˆ°: {self.output_summary_file}")
            print(f"ğŸ“ APIæ—¥å¿—å·²ä¿å­˜åˆ°: {self.api_log_file}")
            
            # 9. æ‰“å°æƒ…ç»ªæ‘˜è¦
            self.print_emotion_summary(emotion_groups)
            
            return final_result
            
        except Exception as e:
            print(f"âŒ æƒ…æ„Ÿåˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return None
    
    def print_emotion_summary(self, emotion_groups: Dict):
        """æ‰“å°æƒ…æ„Ÿåˆ†ææ‘˜è¦"""
        print("\n=== æƒ…æ„Ÿåˆ†ææ‘˜è¦ ===")
        total_lines = sum(len(lines) for lines in emotion_groups.values())
        
        for emotion, lines in emotion_groups.items():
            if lines:
                line_str = ','.join(map(str, lines))
                percentage = (len(lines) / total_lines) * 100 if total_lines > 0 else 0
                print(f"{emotion}: {line_str} ({len(lines)}æ¡, {percentage:.1f}%)")
            else:
                print(f"{emotion}: æ— ")

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python emotion_analysis.py <json_file_path>")
        print("ç¤ºä¾‹: python emotion_analysis.py '/path/to/speaker_results.json'")
        return
    
    json_file_path = sys.argv[1]
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(json_file_path):
        print(f"é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ {json_file_path}")
        return
    
    # åŠ è½½APIé…ç½®
    config_file = 'emovoice_api_config.json'
    if not os.path.exists(config_file):
        print(f"é”™è¯¯ï¼šAPIé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ {config_file}")
        return
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            emovoice_api_config = json.load(f)
    except Exception as e:
        print(f"é”™è¯¯ï¼šæ— æ³•åŠ è½½APIé…ç½®æ–‡ä»¶ {e}")
        return
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ
    analyzer = LLMEmotionAnalyzer(json_file_path, emovoice_api_config)
    result = analyzer.run_emotion_analysis()
    
    if result:
        print("\nğŸ‰ æƒ…æ„Ÿåˆ†æå®Œæˆï¼")
    else:
        print("âŒ æƒ…æ„Ÿåˆ†æå¤±è´¥")

if __name__ == "__main__":
    main()
